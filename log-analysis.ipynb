{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OONcE1hg4cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "744169c8-be04-4ab3-8551-c617f755eb2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UGpNQUMxRiI",
        "outputId": "861b9755-3241-440a-b13c-ebc44d77a99a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files = ['sqli.csv','sqliv2.csv','SQLiV3.csv']\n",
        "df = []\n",
        "for f in csv_files:\n",
        "  try:\n",
        "    dataframe = pd.read_csv('/content/drive/MyDrive/data/SQLi/'+f,encoding='utf-16')\n",
        "  except UnicodeError:\n",
        "    dataframe = pd.read_csv('/content/drive/MyDrive/data/SQLi/'+f,encoding='utf-8')\n",
        "  df.append(dataframe)\n",
        "\n",
        "df = pd.concat(df, ignore_index=True)\n",
        "sentences = df['Sentence'].tolist()\n",
        "labels = df['Label'].tolist()\n",
        "not_sql= (df['Label']==0).sum()\n",
        "sql = (df['Label']==1).sum()\n",
        "print(\"SQL attacks\", sql)\n",
        "print(\"Non-SQL attacks\",not_sql)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3ZyekOLl6Ru",
        "outputId": "ebbad31d-a11b-42b2-b99b-bd9f8b8f3b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SQL attacks 12584\n",
            "Non-SQL attacks 25377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "class NumpyEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return json.JSONEncoder.default(self, obj)\n",
        "\n",
        "glove_file = '/content/drive/MyDrive/data/SQLi/GloVe/glove.840B.300d.txt'\n",
        "glove_embeddings = {}\n",
        "with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        if len(values) != 301:\n",
        "          continue\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        glove_embeddings[word] = vector"
      ],
      "metadata": {
        "id": "rflAyMiisg99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Tokenize sentences\n",
        "tokenized_sentences = [word_tokenize(str(sentence)) for sentence in sentences]\n",
        "seq_tokens = []\n",
        "for sentence in tokenized_sentences:\n",
        "  weighted_sum = np.zeros((300,)) #embedding of whole sentence\n",
        "  count = 0\n",
        "  for word in sentence:\n",
        "    count+=1\n",
        "    if word in glove_embeddings:\n",
        "      embedding = glove_embeddings[word]\n",
        "    else:\n",
        "      embedding = np.zeros((300,))\n",
        "    weighted_sum+= embedding\n",
        "  if count > 0:\n",
        "    seq_tokens.append(weighted_sum / count)\n",
        "  else:\n",
        "    seq_tokens.append(weighted_sum)"
      ],
      "metadata": {
        "id": "Q23cPRTTyUcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "train_sentences, test_sentences, train_labels, test_labels = train_test_split(seq_tokens, labels, test_size=0.2, random_state=42)\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_sentences, train_labels, test_size=0.2, random_state=42)\n",
        "index_train =[] #index where nan\n",
        "index_test = []\n",
        "for i in range(0,len(train_labels)):\n",
        "  if (train_labels[i]=='0'or train_labels[i]=='1'or train_labels[i]==1 or train_labels[i]==0):\n",
        "    train_labels[i]=int(train_labels[i])\n",
        "  else:\n",
        "    index_train.append(i)\n",
        "\n",
        "for i in range(0,len(test_labels)):\n",
        "  if (test_labels[i]=='0'or test_labels[i]=='1'or test_labels[i]==1 or test_labels[i]==0):\n",
        "    test_labels[i]=int(test_labels[i])\n",
        "  else:\n",
        "    index_test.append(i)\n",
        "\n",
        "train_labels = np.delete(train_labels,index_train)\n",
        "test_labels = np.delete(test_labels,index_test)\n",
        "train_sentences = np.delete(train_sentences,index_train,axis = 0)\n",
        "test_sentences = np.delete(test_sentences,index_test, axis = 0)\n",
        "train_labels = [int(x) for x in train_labels] #Convert string labels to int\n",
        "test_labels = [int(x) for x in test_labels]\n",
        "train_dataset = TensorDataset(torch.tensor(train_sentences),torch.tensor(train_labels).unsqueeze(1))\n",
        "test_dataset = TensorDataset(torch.tensor(test_sentences),torch.tensor(test_labels).unsqueeze(1))\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
        "train_labels = torch.tensor(train_labels)"
      ],
      "metadata": {
        "id": "kVkno_qIaANe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "output_dim = 32\n",
        "hidden_dim = 100\n",
        "num_layers = 2\n",
        "dropout = 0.5\n",
        "batch_size = 32\n",
        "lr = 0.001\n",
        "num_epochs = 5\n"
      ],
      "metadata": {
        "id": "2e4-I1XzMGY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch):\n",
        "    # `batch` is a list of tuples (sample, target)\n",
        "    # where `sample` is a tensor of shape (seq_len, input_size)\n",
        "    # and `target` is a tensor of shape (1,)\n",
        "    # We want to convert this list of tuples into a single batch\n",
        "\n",
        "    # Stack the samples along the batch dimension to create a batch of shape (batch_size, seq_len, input_size)\n",
        "    samples = torch.stack([sample for sample, target in batch], dim=0)\n",
        "\n",
        "    # Stack the targets along the batch dimension to create a batch of shape (batch_size,)\n",
        "    targets = torch.stack([target for sample, target in batch], dim=0)\n",
        "\n",
        "    return samples, targets\n"
      ],
      "metadata": {
        "id": "KYxfKDxr1bE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensors = torch.Tensor(train_sentences)\n",
        "X_test_tensors = torch.Tensor(test_sentences)\n",
        "\n",
        "y_train_tensors = torch.Tensor(train_labels)\n",
        "y_test_tensors = torch.Tensor(test_labels)\n",
        "\n",
        "X_train_tensors_final = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
        "X_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1])) "
      ],
      "metadata": {
        "id": "97nRmrBXNuA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM1(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n",
        "        super(LSTM1, self).__init__()\n",
        "        self.num_classes = num_classes #number of classes\n",
        "        self.num_layers = num_layers #number of layers\n",
        "        self.input_size = input_size #input size\n",
        "        self.hidden_size = hidden_size #hidden state\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                          num_layers=num_layers, batch_first=True,bidirectional=False) #lstm\n",
        "        self.fc_1 =  nn.Linear(hidden_size, 128) #fully connected 1\n",
        "        self.fc = nn.Linear(128, num_classes) #fully connected last layer\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self,x):\n",
        "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size) #hidden state\n",
        "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size) #internal state\n",
        "        # Propagate input through LSTM\n",
        "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
        "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
        "        out = self.relu(hn)\n",
        "        out = self.fc_1(out) #first Dense\n",
        "        out = self.relu(out) #relu\n",
        "        out = self.fc(out) #Final Output\n",
        "        return out\n",
        "model = LSTM1(2,32,100,1)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBNr0IbMLoLB",
        "outputId": "0e6f07ef-9bb1-4195-a86d-5461c59a7361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM1(\n",
            "  (lstm): LSTM(32, 100, batch_first=True)\n",
            "  (fc_1): Linear(in_features=100, out_features=128, bias=True)\n",
            "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test_tensors_final.shape)\n",
        "print(X_train_tensors_final.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDZ1BwrChdCq",
        "outputId": "0061cb09-197b-420f-8fc4-a8e3fa049cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([13707, 1, 300])\n",
            "torch.Size([43898, 1, 300])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch\n",
        "import time\n",
        "import os\n",
        "\n",
        "model = LSTM1(1,300,100,1)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.BCELoss()    \n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr) \n",
        "\n",
        "save_path = '/content/drive/My Drive/models/model_params.pt'\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "torch.save(model.state_dict(), save_path)\n",
        "\n",
        "total_loss = 0.0\n",
        "iter = 0\n",
        "\n",
        "min_test_loss = 1\n",
        "#to time the training\n",
        "start_time = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Epoch\",epoch)\n",
        "  running_loss = 0.0\n",
        "  for i, batch in enumerate(train_dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    inputs, targets = batch\n",
        "    outputs = model(inputs.unsqueeze(1).to(torch.float))\n",
        "    outputs = nn.functional.sigmoid(outputs) # Apply sigmoid activation so that values are between 0 and 1\n",
        "    targets = targets.to(torch.float)\n",
        "    batch_loss = criterion(outputs, targets)\n",
        "    batch_loss.backward()\n",
        "    # Clip the gradients to avoid exploding gradients\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    if i % 20 == 0:\n",
        "      # logging.info(f\"Step [{step}/{len(train_dataloader)}], Loss: {loss.item():.4f}\")\n",
        "      print(f'Step [{i}/{len(train_dataloader)}], Loss: {batch_loss.item():.4f}')    \n",
        "    # Update the running loss\n",
        "model.eval()\n",
        "end_time = time.time()\n",
        "elapsed_time_lstm = end_time - start_time\n",
        "print(f'Time taken to train: {elapsed_time_lstm} seconds')\n",
        "\n",
        "model_state_dict = model.state_dict()\n",
        "torch.save(model_state_dict, 'model_params.pt')\n",
        "correct = 0\n",
        "total = 0\n",
        "for i, batch in enumerate(test_dataloader):\n",
        "  optimizer.zero_grad()\n",
        "  inputs, targets = batch\n",
        "  outputs = model(inputs.unsqueeze(1).to(torch.float))\n",
        "  outputs = nn.functional.sigmoid(outputs) # Apply sigmoid activation so that values are between 0 and 1\n",
        "  predicted = torch.round(outputs).int()\n",
        "  predicted = predicted.view(-1)\n",
        "  targets = targets.view(-1)\n",
        "  correct+= (predicted == targets).sum().item()\n",
        "  # count the total number of samples\n",
        "  total += 32\n",
        "accuracy = 100 * correct / total\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOG5IAKN_2y_",
        "outputId": "e2f35a8c-5283-41d4-c178-59a1b182b503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Step [0/1372], Loss: 0.6929\n",
            "Step [20/1372], Loss: 0.5945\n",
            "Step [40/1372], Loss: 0.3679\n",
            "Step [60/1372], Loss: 0.1175\n",
            "Step [80/1372], Loss: 0.0404\n",
            "Step [100/1372], Loss: 0.0692\n",
            "Step [120/1372], Loss: 0.0533\n",
            "Step [140/1372], Loss: 0.1151\n",
            "Step [160/1372], Loss: 0.0404\n",
            "Step [180/1372], Loss: 0.0079\n",
            "Step [200/1372], Loss: 0.0202\n",
            "Step [220/1372], Loss: 0.0526\n",
            "Step [240/1372], Loss: 0.0106\n",
            "Step [260/1372], Loss: 0.1177\n",
            "Step [280/1372], Loss: 0.0044\n",
            "Step [300/1372], Loss: 0.0080\n",
            "Step [320/1372], Loss: 0.0051\n",
            "Step [340/1372], Loss: 0.0085\n",
            "Step [360/1372], Loss: 0.0068\n",
            "Step [380/1372], Loss: 0.0034\n",
            "Step [400/1372], Loss: 0.0065\n",
            "Step [420/1372], Loss: 0.0028\n",
            "Step [440/1372], Loss: 0.0055\n",
            "Step [460/1372], Loss: 0.0496\n",
            "Step [480/1372], Loss: 0.0033\n",
            "Step [500/1372], Loss: 0.0029\n",
            "Step [520/1372], Loss: 0.0217\n",
            "Step [540/1372], Loss: 0.0026\n",
            "Step [560/1372], Loss: 0.0086\n",
            "Step [580/1372], Loss: 0.0064\n",
            "Step [600/1372], Loss: 0.0048\n",
            "Step [620/1372], Loss: 0.0371\n",
            "Step [640/1372], Loss: 0.0033\n",
            "Step [660/1372], Loss: 0.0076\n",
            "Step [680/1372], Loss: 0.0016\n",
            "Step [700/1372], Loss: 0.0541\n",
            "Step [720/1372], Loss: 0.0027\n",
            "Step [740/1372], Loss: 0.0041\n",
            "Step [760/1372], Loss: 0.0027\n",
            "Step [780/1372], Loss: 0.0053\n",
            "Step [800/1372], Loss: 0.0022\n",
            "Step [820/1372], Loss: 0.1672\n",
            "Step [840/1372], Loss: 0.0026\n",
            "Step [860/1372], Loss: 0.0072\n",
            "Step [880/1372], Loss: 0.0086\n",
            "Step [900/1372], Loss: 0.0047\n",
            "Step [920/1372], Loss: 0.0050\n",
            "Step [940/1372], Loss: 0.0023\n",
            "Step [960/1372], Loss: 0.0030\n",
            "Step [980/1372], Loss: 0.0015\n",
            "Step [1000/1372], Loss: 0.0023\n",
            "Step [1020/1372], Loss: 0.0133\n",
            "Step [1040/1372], Loss: 0.0007\n",
            "Step [1060/1372], Loss: 0.0162\n",
            "Step [1080/1372], Loss: 0.0036\n",
            "Step [1100/1372], Loss: 0.0014\n",
            "Step [1120/1372], Loss: 0.0014\n",
            "Step [1140/1372], Loss: 0.0043\n",
            "Step [1160/1372], Loss: 0.0015\n",
            "Step [1180/1372], Loss: 0.0010\n",
            "Step [1200/1372], Loss: 0.0050\n",
            "Step [1220/1372], Loss: 0.2082\n",
            "Step [1240/1372], Loss: 0.0019\n",
            "Step [1260/1372], Loss: 0.0058\n",
            "Step [1280/1372], Loss: 0.0008\n",
            "Step [1300/1372], Loss: 0.0009\n",
            "Step [1320/1372], Loss: 0.0007\n",
            "Step [1340/1372], Loss: 0.0014\n",
            "Step [1360/1372], Loss: 0.0012\n",
            "Epoch 1\n",
            "Step [0/1372], Loss: 0.0024\n",
            "Step [20/1372], Loss: 0.0010\n",
            "Step [40/1372], Loss: 0.0030\n",
            "Step [60/1372], Loss: 0.0231\n",
            "Step [80/1372], Loss: 0.0008\n",
            "Step [100/1372], Loss: 0.2033\n",
            "Step [120/1372], Loss: 0.0012\n",
            "Step [140/1372], Loss: 0.1805\n",
            "Step [160/1372], Loss: 0.0019\n",
            "Step [180/1372], Loss: 0.0071\n",
            "Step [200/1372], Loss: 0.0006\n",
            "Step [220/1372], Loss: 0.0320\n",
            "Step [240/1372], Loss: 0.0082\n",
            "Step [260/1372], Loss: 0.0009\n",
            "Step [280/1372], Loss: 0.1858\n",
            "Step [300/1372], Loss: 0.0031\n",
            "Step [320/1372], Loss: 0.0012\n",
            "Step [340/1372], Loss: 0.0496\n",
            "Step [360/1372], Loss: 0.0021\n",
            "Step [380/1372], Loss: 0.0017\n",
            "Step [400/1372], Loss: 0.0015\n",
            "Step [420/1372], Loss: 0.0118\n",
            "Step [440/1372], Loss: 0.0013\n",
            "Step [460/1372], Loss: 0.0011\n",
            "Step [480/1372], Loss: 0.0006\n",
            "Step [500/1372], Loss: 0.0020\n",
            "Step [520/1372], Loss: 0.0008\n",
            "Step [540/1372], Loss: 0.0005\n",
            "Step [560/1372], Loss: 0.0013\n",
            "Step [580/1372], Loss: 0.0004\n",
            "Step [600/1372], Loss: 0.0005\n",
            "Step [620/1372], Loss: 0.0014\n",
            "Step [640/1372], Loss: 0.0005\n",
            "Step [660/1372], Loss: 0.0079\n",
            "Step [680/1372], Loss: 0.0004\n",
            "Step [700/1372], Loss: 0.0013\n",
            "Step [720/1372], Loss: 0.0025\n",
            "Step [740/1372], Loss: 0.0021\n",
            "Step [760/1372], Loss: 0.0013\n",
            "Step [780/1372], Loss: 0.0016\n",
            "Step [800/1372], Loss: 0.0019\n",
            "Step [820/1372], Loss: 0.0018\n",
            "Step [840/1372], Loss: 0.0023\n",
            "Step [860/1372], Loss: 0.0018\n",
            "Step [880/1372], Loss: 0.0011\n",
            "Step [900/1372], Loss: 0.0012\n",
            "Step [920/1372], Loss: 0.0007\n",
            "Step [940/1372], Loss: 0.0069\n",
            "Step [960/1372], Loss: 0.0063\n",
            "Step [980/1372], Loss: 0.0101\n",
            "Step [1000/1372], Loss: 0.0016\n",
            "Step [1020/1372], Loss: 0.0004\n",
            "Step [1040/1372], Loss: 0.0066\n",
            "Step [1060/1372], Loss: 0.0035\n",
            "Step [1080/1372], Loss: 0.0007\n",
            "Step [1100/1372], Loss: 0.0012\n",
            "Step [1120/1372], Loss: 0.0015\n",
            "Step [1140/1372], Loss: 0.0003\n",
            "Step [1160/1372], Loss: 0.0005\n",
            "Step [1180/1372], Loss: 0.0006\n",
            "Step [1200/1372], Loss: 0.0031\n",
            "Step [1220/1372], Loss: 0.0012\n",
            "Step [1240/1372], Loss: 0.0057\n",
            "Step [1260/1372], Loss: 0.0007\n",
            "Step [1280/1372], Loss: 0.1924\n",
            "Step [1300/1372], Loss: 0.0004\n",
            "Step [1320/1372], Loss: 0.0232\n",
            "Step [1340/1372], Loss: 0.1555\n",
            "Step [1360/1372], Loss: 0.0042\n",
            "Epoch 2\n",
            "Step [0/1372], Loss: 0.0036\n",
            "Step [20/1372], Loss: 0.0025\n",
            "Step [40/1372], Loss: 0.0014\n",
            "Step [60/1372], Loss: 0.0015\n",
            "Step [80/1372], Loss: 0.0020\n",
            "Step [100/1372], Loss: 0.0010\n",
            "Step [120/1372], Loss: 0.0029\n",
            "Step [140/1372], Loss: 0.0016\n",
            "Step [160/1372], Loss: 0.0023\n",
            "Step [180/1372], Loss: 0.0009\n",
            "Step [200/1372], Loss: 0.0006\n",
            "Step [220/1372], Loss: 0.0010\n",
            "Step [240/1372], Loss: 0.0010\n",
            "Step [260/1372], Loss: 0.0124\n",
            "Step [280/1372], Loss: 0.0008\n",
            "Step [300/1372], Loss: 0.0014\n",
            "Step [320/1372], Loss: 0.0024\n",
            "Step [340/1372], Loss: 0.0009\n",
            "Step [360/1372], Loss: 0.0010\n",
            "Step [380/1372], Loss: 0.0007\n",
            "Step [400/1372], Loss: 0.0010\n",
            "Step [420/1372], Loss: 0.0020\n",
            "Step [440/1372], Loss: 0.0004\n",
            "Step [460/1372], Loss: 0.0016\n",
            "Step [480/1372], Loss: 0.0025\n",
            "Step [500/1372], Loss: 0.0016\n",
            "Step [520/1372], Loss: 0.0024\n",
            "Step [540/1372], Loss: 0.0017\n",
            "Step [560/1372], Loss: 0.0021\n",
            "Step [580/1372], Loss: 0.0014\n",
            "Step [600/1372], Loss: 0.0007\n",
            "Step [620/1372], Loss: 0.0008\n",
            "Step [640/1372], Loss: 0.0012\n",
            "Step [660/1372], Loss: 0.0006\n",
            "Step [680/1372], Loss: 0.0017\n",
            "Step [700/1372], Loss: 0.0009\n",
            "Step [720/1372], Loss: 0.0014\n",
            "Step [740/1372], Loss: 0.0011\n",
            "Step [760/1372], Loss: 0.0005\n",
            "Step [780/1372], Loss: 0.0032\n",
            "Step [800/1372], Loss: 0.0013\n",
            "Step [820/1372], Loss: 0.0076\n",
            "Step [840/1372], Loss: 0.0008\n",
            "Step [860/1372], Loss: 0.0019\n",
            "Step [880/1372], Loss: 0.0034\n",
            "Step [900/1372], Loss: 0.0012\n",
            "Step [920/1372], Loss: 0.0013\n",
            "Step [940/1372], Loss: 0.0023\n",
            "Step [960/1372], Loss: 0.0015\n",
            "Step [980/1372], Loss: 0.0024\n",
            "Step [1000/1372], Loss: 0.0011\n",
            "Step [1020/1372], Loss: 0.0003\n",
            "Step [1040/1372], Loss: 0.0010\n",
            "Step [1060/1372], Loss: 0.0009\n",
            "Step [1080/1372], Loss: 0.0007\n",
            "Step [1100/1372], Loss: 0.0012\n",
            "Step [1120/1372], Loss: 0.0005\n",
            "Step [1140/1372], Loss: 0.0005\n",
            "Step [1160/1372], Loss: 0.0003\n",
            "Step [1180/1372], Loss: 0.0003\n",
            "Step [1200/1372], Loss: 0.0037\n",
            "Step [1220/1372], Loss: 0.0008\n",
            "Step [1240/1372], Loss: 0.0015\n",
            "Step [1260/1372], Loss: 0.0023\n",
            "Step [1280/1372], Loss: 0.0013\n",
            "Step [1300/1372], Loss: 0.0017\n",
            "Step [1320/1372], Loss: 0.0011\n",
            "Step [1340/1372], Loss: 0.0020\n",
            "Step [1360/1372], Loss: 0.0003\n",
            "Epoch 3\n",
            "Step [0/1372], Loss: 0.0006\n",
            "Step [20/1372], Loss: 0.0009\n",
            "Step [40/1372], Loss: 0.0005\n",
            "Step [60/1372], Loss: 0.1720\n",
            "Step [80/1372], Loss: 0.0024\n",
            "Step [100/1372], Loss: 0.0012\n",
            "Step [120/1372], Loss: 0.0018\n",
            "Step [140/1372], Loss: 0.0018\n",
            "Step [160/1372], Loss: 0.0059\n",
            "Step [180/1372], Loss: 0.0017\n",
            "Step [200/1372], Loss: 0.0013\n",
            "Step [220/1372], Loss: 0.0009\n",
            "Step [240/1372], Loss: 0.0014\n",
            "Step [260/1372], Loss: 0.0036\n",
            "Step [280/1372], Loss: 0.0014\n",
            "Step [300/1372], Loss: 0.0009\n",
            "Step [320/1372], Loss: 0.0012\n",
            "Step [340/1372], Loss: 0.0011\n",
            "Step [360/1372], Loss: 0.0005\n",
            "Step [380/1372], Loss: 0.0004\n",
            "Step [400/1372], Loss: 0.0017\n",
            "Step [420/1372], Loss: 0.0006\n",
            "Step [440/1372], Loss: 0.0003\n",
            "Step [460/1372], Loss: 0.0010\n",
            "Step [480/1372], Loss: 0.0005\n",
            "Step [500/1372], Loss: 0.0012\n",
            "Step [520/1372], Loss: 0.0009\n",
            "Step [540/1372], Loss: 0.0005\n",
            "Step [560/1372], Loss: 0.0016\n",
            "Step [580/1372], Loss: 0.0015\n",
            "Step [600/1372], Loss: 0.0010\n",
            "Step [620/1372], Loss: 0.0013\n",
            "Step [640/1372], Loss: 0.0016\n",
            "Step [660/1372], Loss: 0.0013\n",
            "Step [680/1372], Loss: 0.0010\n",
            "Step [700/1372], Loss: 0.0012\n",
            "Step [720/1372], Loss: 0.0022\n",
            "Step [740/1372], Loss: 0.0054\n",
            "Step [760/1372], Loss: 0.1539\n",
            "Step [780/1372], Loss: 0.0027\n",
            "Step [800/1372], Loss: 0.0022\n",
            "Step [820/1372], Loss: 0.0011\n",
            "Step [840/1372], Loss: 0.0007\n",
            "Step [860/1372], Loss: 0.0035\n",
            "Step [880/1372], Loss: 0.0019\n",
            "Step [900/1372], Loss: 0.0019\n",
            "Step [920/1372], Loss: 0.0005\n",
            "Step [940/1372], Loss: 0.0049\n",
            "Step [960/1372], Loss: 0.0102\n",
            "Step [980/1372], Loss: 0.0012\n",
            "Step [1000/1372], Loss: 0.0131\n",
            "Step [1020/1372], Loss: 0.0015\n",
            "Step [1040/1372], Loss: 0.0006\n",
            "Step [1060/1372], Loss: 0.0004\n",
            "Step [1080/1372], Loss: 0.0006\n",
            "Step [1100/1372], Loss: 0.0005\n",
            "Step [1120/1372], Loss: 0.0016\n",
            "Step [1140/1372], Loss: 0.0016\n",
            "Step [1160/1372], Loss: 0.0030\n",
            "Step [1180/1372], Loss: 0.0011\n",
            "Step [1200/1372], Loss: 0.0013\n",
            "Step [1220/1372], Loss: 0.0008\n",
            "Step [1240/1372], Loss: 0.0008\n",
            "Step [1260/1372], Loss: 0.0016\n",
            "Step [1280/1372], Loss: 0.0016\n",
            "Step [1300/1372], Loss: 0.0006\n",
            "Step [1320/1372], Loss: 0.0010\n",
            "Step [1340/1372], Loss: 0.0012\n",
            "Step [1360/1372], Loss: 0.0052\n",
            "Epoch 4\n",
            "Step [0/1372], Loss: 0.1779\n",
            "Step [20/1372], Loss: 0.0019\n",
            "Step [40/1372], Loss: 0.0023\n",
            "Step [60/1372], Loss: 0.0016\n",
            "Step [80/1372], Loss: 0.0009\n",
            "Step [100/1372], Loss: 0.0024\n",
            "Step [120/1372], Loss: 0.0022\n",
            "Step [140/1372], Loss: 0.0031\n",
            "Step [160/1372], Loss: 0.0020\n",
            "Step [180/1372], Loss: 0.0022\n",
            "Step [200/1372], Loss: 0.1991\n",
            "Step [220/1372], Loss: 0.0015\n",
            "Step [240/1372], Loss: 0.0022\n",
            "Step [260/1372], Loss: 0.0012\n",
            "Step [280/1372], Loss: 0.1501\n",
            "Step [300/1372], Loss: 0.0026\n",
            "Step [320/1372], Loss: 0.0012\n",
            "Step [340/1372], Loss: 0.1939\n",
            "Step [360/1372], Loss: 0.0018\n",
            "Step [380/1372], Loss: 0.0020\n",
            "Step [400/1372], Loss: 0.0013\n",
            "Step [420/1372], Loss: 0.0016\n",
            "Step [440/1372], Loss: 0.0011\n",
            "Step [460/1372], Loss: 0.0009\n",
            "Step [480/1372], Loss: 0.0008\n",
            "Step [500/1372], Loss: 0.1879\n",
            "Step [520/1372], Loss: 0.0010\n",
            "Step [540/1372], Loss: 0.0006\n",
            "Step [560/1372], Loss: 0.0010\n",
            "Step [580/1372], Loss: 0.0008\n",
            "Step [600/1372], Loss: 0.0041\n",
            "Step [620/1372], Loss: 0.0011\n",
            "Step [640/1372], Loss: 0.0187\n",
            "Step [660/1372], Loss: 0.1775\n",
            "Step [680/1372], Loss: 0.0015\n",
            "Step [700/1372], Loss: 0.0009\n",
            "Step [720/1372], Loss: 0.0027\n",
            "Step [740/1372], Loss: 0.0010\n",
            "Step [760/1372], Loss: 0.0007\n",
            "Step [780/1372], Loss: 0.0009\n",
            "Step [800/1372], Loss: 0.0009\n",
            "Step [820/1372], Loss: 0.0386\n",
            "Step [840/1372], Loss: 0.0033\n",
            "Step [860/1372], Loss: 0.0022\n",
            "Step [880/1372], Loss: 0.0015\n",
            "Step [900/1372], Loss: 0.0002\n",
            "Step [920/1372], Loss: 0.0006\n",
            "Step [940/1372], Loss: 0.0003\n",
            "Step [960/1372], Loss: 0.0022\n",
            "Step [980/1372], Loss: 0.0012\n",
            "Step [1000/1372], Loss: 0.0061\n",
            "Step [1020/1372], Loss: 0.0006\n",
            "Step [1040/1372], Loss: 0.0008\n",
            "Step [1060/1372], Loss: 0.0005\n",
            "Step [1080/1372], Loss: 0.0006\n",
            "Step [1100/1372], Loss: 0.0014\n",
            "Step [1120/1372], Loss: 0.0022\n",
            "Step [1140/1372], Loss: 0.0008\n",
            "Step [1160/1372], Loss: 0.0013\n",
            "Step [1180/1372], Loss: 0.0008\n",
            "Step [1200/1372], Loss: 0.0003\n",
            "Step [1220/1372], Loss: 0.0012\n",
            "Step [1240/1372], Loss: 0.0007\n",
            "Step [1260/1372], Loss: 0.0010\n",
            "Step [1280/1372], Loss: 0.0002\n",
            "Step [1300/1372], Loss: 0.0003\n",
            "Step [1320/1372], Loss: 0.0271\n",
            "Step [1340/1372], Loss: 0.0008\n",
            "Step [1360/1372], Loss: 0.0004\n",
            "Time taken to train: 65.52907347679138 seconds\n",
            "Accuracy: 99.69405594405595\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_10_inputs = y_test_tensors[-10:]\n",
        "last_10_labels = test_labels[-10:]\n",
        "last_10_predicted = outputs[-10:]\n",
        "print(\"+------------+-------+----------+\")\n",
        "print(\"| Input      | Label | Predicted|\")\n",
        "print(\"+------------+-------+----------+\")\n",
        "for i in range(10):\n",
        "    input_str = str(last_10_inputs[i].tolist())\n",
        "    label_str = str(last_10_labels[i])\n",
        "    predicted_str = str(torch.round(last_10_predicted[i]).item())\n",
        "    print(f\"| {input_str:<10} | {label_str:<5} | {predicted_str:<8} |\")\n",
        "print(\"+------------+-------+----------+\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVZwxLPWXEjs",
        "outputId": "8fc70266-a388-4cc7-89b9-7ebc1d9695c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-------+----------+\n",
            "| Input      | Label | Predicted|\n",
            "+------------+-------+----------+\n",
            "| 0.0        | 0     | 0.0      |\n",
            "| 1.0        | 1     | 1.0      |\n",
            "| 0.0        | 0     | 0.0      |\n",
            "| 0.0        | 0     | 0.0      |\n",
            "| 1.0        | 1     | 1.0      |\n",
            "| 0.0        | 0     | 0.0      |\n",
            "| 0.0        | 0     | 0.0      |\n",
            "| 0.0        | 0     | 0.0      |\n",
            "| 0.0        | 0     | 0.0      |\n",
            "| 0.0        | 0     | 0.0      |\n",
            "+------------+-------+----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random forest\n",
        "import sklearn\n",
        "import pickle\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from joblib import dump,load\n",
        "\n",
        "random_forest = RandomForestClassifier(bootstrap = True, random_state = 18)\n",
        "start_time = time.time()\n",
        "random_forest.fit(train_sentences, train_labels)\n",
        "dump(random_forest, 'random_forest_model.joblib')\n",
        "end_time = time.time()\n",
        "elapsed_time_forest = end_time-start_time\n",
        "print(f'Time taken to train RandomForest: {elapsed_time_forest} seconds')\n",
        "predictions = random_forest.predict(test_sentences)\n",
        "accuracy_rf = random_forest.score(X_test_tensors_final.squeeze(1), predictions)\n",
        "print(\"Accuracy score\",accuracy_rf)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtvU_hwSruLr",
        "outputId": "d8d772b9-8a23-4e5c-88b1-75198935b370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to train RandomForest: 69.04466676712036 seconds\n",
            "Accuracy score 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "svm_classifier = svm.SVC(kernel='linear')\n",
        "print(svm_classifier)\n",
        "start_time = time.time()\n",
        "svm_classifier.fit(train_sentences, train_labels)\n",
        "end_time = time.time()\n",
        "elapsed_time_svm = end_time-start_time\n",
        "print(f'Time taken to train SVM: {elapsed_time_svm} seconds')\n",
        "y_pred = svm_classifier.predict(test_sentences)\n",
        "accuracy_svm= svm_classifier.score(test_sentences, test_labels)\n",
        "print(\"Accuracy:\", accuracy_svm)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqtOyZ1O-F0F",
        "outputId": "ac4ca4e7-b064-46b8-d03a-5e7ca7e49004"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC(kernel='linear')\n",
            "Time taken to train SVM: 19.330122470855713 seconds\n",
            "Accuracy: 0.9939446997884293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "score1 = svm_classifier.score(test_sentences, test_labels)\n",
        "score2 = random_forest.score(X_test_tensors_final.squeeze(1), predictions)\n",
        "score3 = accuracy\n",
        "plt.figure()\n",
        "colors = ['red','green','blue']\n",
        "# Plot the points using the scatter function\n",
        "plt.scatter(['SVM','Random_forest','LSTM'],[score1*100,score2*100,score3],c=colors)\n",
        "plt.plot(['SVM','LSTM','Random_forest'],[score1*100,score2*100,score3])\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "OwGVbux7h0XS",
        "outputId": "053b39e0-fdaa-4f3a-d985-96fec182b4e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}